{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: PyTorch \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: GPU/Device Agnostic Code\n",
    "**Goal:** Write code that runs on CPU, CUDA, or MPS (Mac) automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "\n",
    "sample_input = torch.randn(1, 10).to(device)\n",
    "type(sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: MNIST Project \n",
    "Step 1: What is MNIST & Downloading Data\n",
    "\n",
    "Concept: MNIST is the \"Hello World\" of Machine Learning. It contains 70,000 images of handwritten digits (0-9).\n",
    "\n",
    "The Goal: Teach the computer to look at a grid of pixels and say \"That is a 7\".\n",
    "\n",
    "The Data: Each image is grayscale and exactly 28×28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# transform=ToTensor() converts the image (0-255) to a Torch Tensor (0.0-1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do for Testing\n",
    "testing_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing One Image & Understanding Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img , label = training_data[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.7255, 1.0000, 0.9922,\n",
       "          0.9922, 0.9020, 0.5176, 0.5176, 0.1216, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0353, 0.2784, 0.9490, 0.9882, 0.9882, 0.8941,\n",
       "          0.9059, 0.9882, 0.9882, 0.9882, 0.6549, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.1098, 0.6510, 0.9882, 0.9882, 0.9216, 0.3608, 0.0000,\n",
       "          0.0549, 0.5569, 0.9882, 0.9882, 0.5882, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0471, 0.8000, 0.9882, 0.9176, 0.5961, 0.1725, 0.0000, 0.0000,\n",
       "          0.1882, 0.8824, 0.9882, 0.7059, 0.0627, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0471,\n",
       "          0.6431, 0.9882, 0.9098, 0.2392, 0.0000, 0.0000, 0.0000, 0.0235,\n",
       "          0.7020, 0.9882, 0.9882, 0.2353, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "          0.9882, 0.9882, 0.2980, 0.0000, 0.0000, 0.0000, 0.1725, 0.7804,\n",
       "          0.9882, 0.9882, 0.9882, 0.2353, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3490,\n",
       "          0.9882, 0.8941, 0.1255, 0.0000, 0.0000, 0.3882, 0.9059, 0.9569,\n",
       "          0.8627, 0.9882, 0.7961, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6627,\n",
       "          0.9882, 0.8118, 0.3804, 0.3804, 0.8078, 0.9176, 0.9529, 0.1255,\n",
       "          0.6157, 0.9882, 0.5686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2353,\n",
       "          0.9882, 0.9882, 0.9882, 0.9882, 0.9882, 0.7843, 0.0863, 0.0431,\n",
       "          0.7765, 0.9059, 0.1608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1020,\n",
       "          0.5137, 0.8784, 0.9882, 0.9882, 0.5569, 0.0431, 0.0000, 0.3216,\n",
       "          0.9882, 0.8000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0510, 0.9922,\n",
       "          0.9922, 0.5529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3216, 0.9882,\n",
       "          0.8627, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8157, 0.9882,\n",
       "          0.3765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.9922, 0.9686,\n",
       "          0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745, 0.9922, 0.7804,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1255, 0.8471, 0.9569, 0.1020,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9882, 0.9451, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.1294, 0.7843, 0.9765, 0.9882, 0.3608, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.3333, 0.9882, 0.9882, 0.5569, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.3333, 0.9882, 0.7843, 0.0431, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display one Image in MatplotLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19326261d10>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.squeeze() , cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation for the Input Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concept: We are building a Linear (Feed-Forward) Network,\n",
    "\n",
    "A Linear Layer consists of neurons in a single vertical line.\n",
    "\n",
    "Our image is a square grid (28×28).\n",
    "\n",
    "The Division: We must \"cut\" the image row by row and stack them into one long line.\n",
    "\n",
    "The Calculation:\n",
    "\n",
    "Height×Width=Total Input Features\n",
    "28×28=784\n",
    "So, our Input Layer must have 784 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Architecture (1 Input, 1 Hidden, 1 Output\n",
    "The Concept: We will build the simplest standard network.\n",
    "\n",
    "Input Layer (784): Receives the pixels.\n",
    "\n",
    "Hidden Layer (128): The \"brain\" that learns shapes (loops, lines). We pick 128 because it's enough to learn but not too big.\n",
    "\n",
    "Output Layer (10): The final decision. We have 10 digits (0-9), so we need 10 output scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(784,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.layers(x)\n",
    "        return logits\n",
    "\n",
    "model = SimpleNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Batch Size (The Stack)\n",
    "\n",
    "The Concept: Think of the model like a teacher grading exams.\n",
    "\n",
    "Batch Size = 1: The teacher grades 1 exam, updates the grade book, then picks up the next exam. (Too slow).\n",
    "\n",
    "Batch Size = 64: The teacher picks up a stack of 64 exams, grades them all at once, and updates the grade book one time for the whole stack. (Much faster).\n",
    "\n",
    "We use DataLoader to create these \"stacks\" for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938 -- 157\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create stacks\n",
    "train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(testing_data, batch_size=64, shuffle=True)\n",
    "# do for Test_data\n",
    "\n",
    "print(len(train_loader),\"--\",len(test_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Loss = 2.2587\n",
      "Batch 100: Loss = 0.4718\n",
      "Batch 200: Loss = 0.2364\n",
      "Batch 300: Loss = 0.3395\n",
      "Batch 400: Loss = 0.1946\n",
      "Batch 500: Loss = 0.3256\n",
      "Batch 600: Loss = 0.1262\n",
      "Batch 700: Loss = 0.2901\n",
      "Batch 800: Loss = 0.4627\n",
      "Batch 900: Loss = 0.0775\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.6%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
